{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a11e9375-c234-4052-9644-b2ed50bccf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Structured AI-friendly data written to: model_ai_ready5.txt\n",
      "ðŸ“Š Found 16 sheets with names: ['Assumptions & Inputs', 'SF Breakdown', 'Sources & Uses', 'Monthly PF Cash Flow', 'Pro Forma (Annual)', 'Untrended Pro Forma', 'Investor Returns - Pari Passu', 'Investor Returns - Sep Pref Pay', 'Budget to Convert Existing Bldg', 'Budget for New Bldg', 'Property Data', 'Rental Income Model', '5 Year Model', '5 Year Summary', 'RE Tax UW', 'Comps']\n"
     ]
    }
   ],
   "source": [
    "#getting flat txt for AI and removes the =None\n",
    "\n",
    "import zipfile\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "xlsx_path = 'model.xlsx'\n",
    "unpack_dir = Path('model_unpacked')\n",
    "output_txt = 'model_ai_ready5.txt'\n",
    "\n",
    "# Step 1: Unpack\n",
    "with zipfile.ZipFile(xlsx_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unpack_dir)\n",
    "\n",
    "# Step 2: Load shared strings\n",
    "shared_strings_path = unpack_dir / 'xl' / 'sharedStrings.xml'\n",
    "shared_strings = []\n",
    "if shared_strings_path.exists():\n",
    "    tree = ET.parse(shared_strings_path)\n",
    "    root = tree.getroot()\n",
    "    ns = {'a': root.tag.split('}')[0].strip('{')}\n",
    "    for si in root.findall('a:si', ns):\n",
    "        text_elems = si.findall('.//a:t', ns)\n",
    "        text = ''.join(t.text for t in text_elems if t.text)\n",
    "        shared_strings.append(text)\n",
    "\n",
    "# Step 3: Load sheet names and their relationship IDs\n",
    "sheet_rid_to_name = {}\n",
    "workbook_path = unpack_dir / 'xl' / 'workbook.xml'\n",
    "tree = ET.parse(workbook_path)\n",
    "root = tree.getroot()\n",
    "ns = {'a': root.tag.split('}')[0].strip('{')}\n",
    "# Look for r:id attribute which links to relationships\n",
    "for sheet in root.findall('.//a:sheet', ns):\n",
    "    r_id = sheet.attrib.get('{http://schemas.openxmlformats.org/officeDocument/2006/relationships}id')\n",
    "    if not r_id:\n",
    "        # Try without namespace prefix\n",
    "        r_id = sheet.attrib.get('r:id')\n",
    "    name = sheet.attrib['name']\n",
    "    if r_id:\n",
    "        sheet_rid_to_name[r_id] = name\n",
    "\n",
    "# Step 4: Load relationships to map rIds to actual files\n",
    "rid_to_file = {}\n",
    "rels_path = unpack_dir / 'xl' / '_rels' / 'workbook.xml.rels'\n",
    "if rels_path.exists():\n",
    "    tree = ET.parse(rels_path)\n",
    "    root = tree.getroot()\n",
    "    ns = {'a': root.tag.split('}')[0].strip('{')}\n",
    "    for relationship in root.findall('a:Relationship', ns):\n",
    "        r_id = relationship.attrib['Id']\n",
    "        target = relationship.attrib['Target']\n",
    "        if 'worksheets/' in target:\n",
    "            # Extract just the filename\n",
    "            filename = target.split('/')[-1]\n",
    "            rid_to_file[r_id] = filename\n",
    "\n",
    "# Step 5: Create final mapping from filename to sheet name\n",
    "file_to_name = {}\n",
    "for r_id, sheet_name in sheet_rid_to_name.items():\n",
    "    if r_id in rid_to_file:\n",
    "        filename = rid_to_file[r_id]\n",
    "        file_to_name[filename] = sheet_name\n",
    "\n",
    "# Step 6: Read sheet data and formulas\n",
    "output_lines = []\n",
    "sheets_dir = unpack_dir / 'xl' / 'worksheets'\n",
    "for sheet_file in sorted(sheets_dir.glob('sheet*.xml')):\n",
    "    filename = sheet_file.name\n",
    "    sheet_name = file_to_name.get(filename, filename.replace('.xml', ''))\n",
    "    output_lines.append(f\"\\n=== Sheet: {sheet_name} ===\\n\")\n",
    "    \n",
    "    tree = ET.parse(sheet_file)\n",
    "    root = tree.getroot()\n",
    "    ns = {'a': root.tag.split('}')[0].strip('{')}\n",
    "    \n",
    "    for c in root.findall('.//a:sheetData//a:row//a:c', ns):\n",
    "        cell_ref = c.attrib.get('r', '')\n",
    "        cell_type = c.attrib.get('t', '')\n",
    "        formula = c.find('a:f', ns)\n",
    "        value = c.find('a:v', ns)\n",
    "        \n",
    "        # Get cell value\n",
    "        if cell_type == 's' and value is not None:\n",
    "            val = shared_strings[int(value.text)]\n",
    "        elif value is not None:\n",
    "            val = value.text\n",
    "        else:\n",
    "            val = ''\n",
    "        \n",
    "        # Only output if we have meaningful content\n",
    "        if formula is not None and formula.text is not None and formula.text.strip():\n",
    "            output_lines.append(f\"{cell_ref}: {formula.text.strip()}\")\n",
    "        elif val and str(val).strip() and str(val).strip() != '0':\n",
    "            output_lines.append(f\"{cell_ref}: {str(val).strip()}\")\n",
    "\n",
    "# Step 7: Save\n",
    "with open(output_txt, 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(output_lines))\n",
    "\n",
    "print(f\"âœ… Structured AI-friendly data written to: {output_txt}\")\n",
    "print(f\"ðŸ“Š Found {len(file_to_name)} sheets with names: {list(file_to_name.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5692afc4-8266-4349-8326-192a74e036a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel formulas only \n",
    "\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "def extract_formulas_and_text(file_path):\n",
    "    \"\"\"\n",
    "    Extract formulas and text labels from Excel file in compact format\n",
    "    Skip empty cells and cells with only values\n",
    "    \"\"\"\n",
    "    wb = load_workbook(file_path, data_only=False)  # data_only=False to get formulas\n",
    "    results = []\n",
    "    \n",
    "    for sheet_name in wb.sheetnames:\n",
    "        sheet = wb[sheet_name]\n",
    "        \n",
    "        # Iterate through all cells with content\n",
    "        for row in sheet.iter_rows():\n",
    "            for cell in row:\n",
    "                if cell.value is not None:\n",
    "                    cell_address = cell.coordinate\n",
    "                    \n",
    "                    # Check if cell contains a formula\n",
    "                    if isinstance(cell.value, str) and cell.value.startswith('='):\n",
    "                        formula = cell.value\n",
    "                        results.append(f\"{sheet_name}|{cell_address}|{formula}\")\n",
    "                    \n",
    "                    # Check if cell contains text (labels) - not numbers, not formulas\n",
    "                    elif isinstance(cell.value, str) and not cell.value.startswith('='):\n",
    "                        text_value = cell.value.strip()\n",
    "                        if text_value:  # Skip empty strings\n",
    "                            results.append(f\"{sheet_name}|{cell_address}|{text_value}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_to_file(results, output_file):\n",
    "    \"\"\"Save results to text file\"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for line in results:\n",
    "            f.write(line + '\\n')\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"model.xlsx\"  # Replace with your file path\n",
    "    output_file = \"extracted_formulas.txt\"\n",
    "    \n",
    "    try:\n",
    "        results = extract_formulas_and_text(file_path)\n",
    "        \n",
    "        # Print results\n",
    "        for result in results:\n",
    "            print(result)\n",
    "        \n",
    "        # Save to file\n",
    "        save_to_file(results, output_file)\n",
    "        print(f\"\\nExtracted {len(results)} items and saved to {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df409f0a-1e47-4b02-a6dc-6ae57114efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "def create_sheet_abbreviation(sheet_name, sheet_index):\n",
    "    \"\"\"\n",
    "    Create abbreviated sheet name: s{number}-{2 letters}\n",
    "    e.g., 'Investor Returns - Pari Passu' -> 's1-ir'\n",
    "    \"\"\"\n",
    "    # Take first 2 letters of the sheet name (ignoring spaces and special chars)\n",
    "    clean_name = ''.join(c.lower() for c in sheet_name if c.isalpha())\n",
    "    abbrev = clean_name[:2] if len(clean_name) >= 2 else clean_name\n",
    "    return f\"s{sheet_index}-{abbrev}\"\n",
    "\n",
    "def replace_sheet_names_in_formulas(text, sheet_mapping):\n",
    "    \"\"\"\n",
    "    Replace all sheet names in formulas with abbreviated versions\n",
    "    \"\"\"\n",
    "    # Create reverse mapping (full name -> abbreviation)\n",
    "    reverse_mapping = {full_name: abbrev for abbrev, full_name in sheet_mapping.items()}\n",
    "    \n",
    "    # Sort by length (longest first) to avoid partial replacements\n",
    "    sorted_sheets = sorted(reverse_mapping.keys(), key=len, reverse=True)\n",
    "    \n",
    "    for full_name in sorted_sheets:\n",
    "        abbrev = reverse_mapping[full_name]\n",
    "        # Replace sheet references in formulas like 'Sheet Name'! with abbrev!\n",
    "        text = text.replace(f\"'{full_name}'!\", f\"{abbrev}!\")\n",
    "        # Also handle unquoted sheet names (if no spaces)\n",
    "        if ' ' not in full_name and '-' not in full_name:\n",
    "            text = text.replace(f\"{full_name}!\", f\"{abbrev}!\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "def extract_formulas_and_text(file_path):\n",
    "    \"\"\"\n",
    "    Extract formulas and text labels from Excel file in compact format\n",
    "    Skip empty cells and cells with only values\n",
    "    \"\"\"\n",
    "    wb = load_workbook(file_path, data_only=False)  # data_only=False to get formulas\n",
    "    results = []\n",
    "    sheet_mapping = {}\n",
    "    \n",
    "    # First pass: create sheet mapping\n",
    "    for sheet_index, sheet_name in enumerate(wb.sheetnames, 1):\n",
    "        sheet_abbrev = create_sheet_abbreviation(sheet_name, sheet_index)\n",
    "        sheet_mapping[sheet_abbrev] = sheet_name\n",
    "    \n",
    "    # Second pass: extract data\n",
    "    for sheet_index, sheet_name in enumerate(wb.sheetnames, 1):\n",
    "        sheet = wb[sheet_name]\n",
    "        sheet_abbrev = create_sheet_abbreviation(sheet_name, sheet_index)\n",
    "        \n",
    "        # Iterate through all cells with content\n",
    "        for row in sheet.iter_rows():\n",
    "            for cell in row:\n",
    "                if cell.value is not None:\n",
    "                    cell_address = cell.coordinate\n",
    "                    \n",
    "                    # Check if cell contains a formula\n",
    "                    if isinstance(cell.value, str) and cell.value.startswith('='):\n",
    "                        formula = cell.value\n",
    "                        # Replace sheet names in formula\n",
    "                        formula = replace_sheet_names_in_formulas(formula, sheet_mapping)\n",
    "                        results.append(f\"{sheet_abbrev}|{cell_address}|{formula}\")\n",
    "                    \n",
    "                    # Check if cell contains text (labels) - not numbers, not formulas\n",
    "                    elif isinstance(cell.value, str) and not cell.value.startswith('='):\n",
    "                        text_value = cell.value.strip()\n",
    "                        if text_value:  # Skip empty strings\n",
    "                            results.append(f\"{sheet_abbrev}|{cell_address}|{text_value}\")\n",
    "    \n",
    "    return results, sheet_mapping\n",
    "\n",
    "def save_to_file(results, sheet_mapping, output_file):\n",
    "    \"\"\"Save results to text file with sheet mapping\"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        # Write sheet mapping at the top\n",
    "        f.write(\"=== SHEET MAPPING ===\\n\")\n",
    "        for abbrev, full_name in sheet_mapping.items():\n",
    "            f.write(f\"{abbrev} = {full_name}\\n\")\n",
    "        f.write(\"\\n=== FORMULAS & TEXT ===\\n\")\n",
    "        \n",
    "        # Write extracted data\n",
    "        for line in results:\n",
    "            f.write(line + '\\n')\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"model.xlsx\"  # Replace with your file path\n",
    "    output_file = \"extracted_formulas3.txt\"\n",
    "    \n",
    "    try:\n",
    "        results, sheet_mapping = extract_formulas_and_text(file_path)\n",
    "        \n",
    "        # Print sheet mapping\n",
    "        print(\"=== SHEET MAPPING ===\")\n",
    "        for abbrev, full_name in sheet_mapping.items():\n",
    "            print(f\"{abbrev} = {full_name}\")\n",
    "        print(\"\\n=== FORMULAS & TEXT ===\")\n",
    "        \n",
    "        # Print results\n",
    "        for result in results:\n",
    "            print(result)\n",
    "        \n",
    "        # Save to file\n",
    "        save_to_file(results, sheet_mapping, output_file)\n",
    "        print(f\"\\nExtracted {len(results)} items and saved to {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88eeec4a-6825-41a2-bacb-7a0cd0e58851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 5 formulas and 3 labels\n",
      "Graph has 8 nodes and 8 edges\n",
      "\n",
      "=== TOP 3 CRITICAL PATHS ===\n",
      "\n",
      "Path 1 (Length: 4):\n",
      "  s1-as!B5 â†’\n",
      "    Label: Base Cost\n",
      "  s2-sf!C11 â†’\n",
      "    Formula: =s1-as!B5*1.2\n",
      "  s2-sf!E11 â†’\n",
      "    Formula: =C11+D11\n",
      "  s4-ou!Z99 (OUTPUT)\n",
      "    Formula: =s3-ca!A1+s2-sf!E11\n",
      "\n",
      "Path 2 (Length: 4):\n",
      "  s1-as!B6 â†’\n",
      "    Label: Additional Cost\n",
      "  s2-sf!D11 â†’\n",
      "    Formula: =s1-as!B6*0.8\n",
      "  s2-sf!E11 â†’\n",
      "    Formula: =C11+D11\n",
      "  s4-ou!Z99 (OUTPUT)\n",
      "    Formula: =s3-ca!A1+s2-sf!E11\n",
      "\n",
      "Path 3 (Length: 3):\n",
      "  s2-sf!K11 â†’\n",
      "    Label: Mech New\n",
      "  s3-ca!A1 â†’\n",
      "    Formula: =s2-sf!E11*s2-sf!K11\n",
      "  s4-ou!Z99 (OUTPUT)\n",
      "    Formula: =s3-ca!A1+s2-sf!E11\n",
      "\n",
      "=== SAMPLE IMPACT ANALYSIS ===\n",
      "=== IMPACT ANALYSIS FOR s4-ou!Z99 ===\n",
      "Depends on 7 cells:\n",
      "  â† s2-sf!D11\n",
      "  â† s1-as!B5\n",
      "  â† s2-sf!C11\n",
      "  â† s3-ca!A1\n",
      "  â† s1-as!B6\n",
      "  â† s2-sf!E11\n",
      "  â† s2-sf!K11\n",
      "\n",
      "Affects 0 cells:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "class ExcelDependencyAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.graph = nx.DiGraph()\n",
    "        self.formulas = {}\n",
    "        self.labels = {}\n",
    "        self.sheet_mapping = {}\n",
    "    \n",
    "    def parse_cell_reference(self, ref):\n",
    "        \"\"\"Parse cell reference like s2-sf!E11 or E11\"\"\"\n",
    "        if '!' in ref:\n",
    "            sheet, cell = ref.split('!')\n",
    "            return f\"{sheet}!{cell}\"\n",
    "        return ref\n",
    "    \n",
    "    def extract_cell_references(self, formula):\n",
    "        \"\"\"Extract all cell references from a formula\"\"\"\n",
    "        # Pattern to match cell references like A1, $A$1, A1:B5, s2-sf!A1, etc.\n",
    "        pattern = r'(?:s\\d+-\\w+!)?(?:\\$?[A-Z]+\\$?\\d+(?::\\$?[A-Z]+\\$?\\d+)?)'\n",
    "        references = re.findall(pattern, formula)\n",
    "        \n",
    "        # Clean up and expand ranges\n",
    "        cells = []\n",
    "        for ref in references:\n",
    "            if ':' in ref:\n",
    "                # Handle ranges - for simplicity, just take the first cell\n",
    "                # In practice, you might want to expand the full range\n",
    "                cells.append(ref.split(':')[0])\n",
    "            else:\n",
    "                cells.append(ref)\n",
    "        \n",
    "        return [self.parse_cell_reference(cell) for cell in cells]\n",
    "    \n",
    "    def parse_input_data(self, data_lines):\n",
    "        \"\"\"Parse the input format: s2-sf|E11|=C11+D11\"\"\"\n",
    "        for line in data_lines:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith('==='):\n",
    "                continue\n",
    "            \n",
    "            parts = line.split('|')\n",
    "            if len(parts) != 3:\n",
    "                continue\n",
    "                \n",
    "            sheet_cell = f\"{parts[0]}!{parts[1]}\"\n",
    "            content = parts[2]\n",
    "            \n",
    "            if content.startswith('='):\n",
    "                # It's a formula\n",
    "                self.formulas[sheet_cell] = content\n",
    "                dependencies = self.extract_cell_references(content)\n",
    "                \n",
    "                # Add edges to graph\n",
    "                for dep in dependencies:\n",
    "                    # Make sure dependency has sheet prefix\n",
    "                    if '!' not in dep:\n",
    "                        dep = f\"{parts[0]}!{dep}\"\n",
    "                    \n",
    "                    self.graph.add_edge(dep, sheet_cell)\n",
    "            else:\n",
    "                # It's a label/text\n",
    "                self.labels[sheet_cell] = content\n",
    "                # Add as node (might be referenced by formulas)\n",
    "                self.graph.add_node(sheet_cell)\n",
    "    \n",
    "    def find_output_cells(self):\n",
    "        \"\"\"Find cells that are likely outputs (no outgoing dependencies)\"\"\"\n",
    "        output_cells = []\n",
    "        for node in self.graph.nodes():\n",
    "            if self.graph.out_degree(node) == 0 and node in self.formulas:\n",
    "                output_cells.append(node)\n",
    "        return output_cells\n",
    "    \n",
    "    def find_input_cells(self):\n",
    "        \"\"\"Find cells that are likely inputs (no incoming dependencies)\"\"\"\n",
    "        input_cells = []\n",
    "        for node in self.graph.nodes():\n",
    "            if self.graph.in_degree(node) == 0:\n",
    "                input_cells.append(node)\n",
    "        return input_cells\n",
    "    \n",
    "    def get_critical_paths(self, max_paths=10):\n",
    "        \"\"\"Find critical paths from inputs to outputs\"\"\"\n",
    "        if not nx.is_directed_acyclic_graph(self.graph):\n",
    "            print(\"Warning: Graph contains cycles!\")\n",
    "            # Remove cycles for analysis\n",
    "            self.graph = nx.DiGraph([(u, v) for u, v in self.graph.edges() \n",
    "                                   if not nx.has_path(self.graph, v, u)])\n",
    "        \n",
    "        outputs = self.find_output_cells()\n",
    "        inputs = self.find_input_cells()\n",
    "        \n",
    "        critical_paths = []\n",
    "        \n",
    "        for output in outputs[:max_paths]:  # Limit outputs to analyze\n",
    "            for input_cell in inputs:\n",
    "                if nx.has_path(self.graph, input_cell, output):\n",
    "                    try:\n",
    "                        path = nx.shortest_path(self.graph, input_cell, output)\n",
    "                        if len(path) > 2:  # Only show meaningful paths\n",
    "                            critical_paths.append({\n",
    "                                'path': path,\n",
    "                                'length': len(path),\n",
    "                                'input': input_cell,\n",
    "                                'output': output\n",
    "                            })\n",
    "                    except nx.NetworkXNoPath:\n",
    "                        continue\n",
    "        \n",
    "        # Sort by path length (longest first)\n",
    "        critical_paths.sort(key=lambda x: x['length'], reverse=True)\n",
    "        return critical_paths\n",
    "    \n",
    "    def analyze_cell_impact(self, cell):\n",
    "        \"\"\"Analyze what cells are affected if this cell changes\"\"\"\n",
    "        if cell not in self.graph:\n",
    "            return []\n",
    "        \n",
    "        # Find all descendants (cells that depend on this cell)\n",
    "        descendants = list(nx.descendants(self.graph, cell))\n",
    "        return descendants\n",
    "    \n",
    "    def trace_cell_dependencies(self, cell):\n",
    "        \"\"\"Trace all dependencies of a cell backwards\"\"\"\n",
    "        if cell not in self.graph:\n",
    "            return []\n",
    "        \n",
    "        # Find all ancestors (cells this cell depends on)\n",
    "        ancestors = list(nx.ancestors(self.graph, cell))\n",
    "        return ancestors\n",
    "    \n",
    "    def print_critical_paths(self, max_paths=5):\n",
    "        \"\"\"Print the critical paths in a readable format\"\"\"\n",
    "        paths = self.get_critical_paths(max_paths)\n",
    "        \n",
    "        print(f\"=== TOP {min(len(paths), max_paths)} CRITICAL PATHS ===\\n\")\n",
    "        \n",
    "        for i, path_info in enumerate(paths[:max_paths], 1):\n",
    "            path = path_info['path']\n",
    "            print(f\"Path {i} (Length: {path_info['length']}):\")\n",
    "            \n",
    "            for j, cell in enumerate(path):\n",
    "                if j < len(path) - 1:\n",
    "                    print(f\"  {cell} â†’\")\n",
    "                else:\n",
    "                    print(f\"  {cell} (OUTPUT)\")\n",
    "                \n",
    "                # Show formula if available\n",
    "                if cell in self.formulas:\n",
    "                    print(f\"    Formula: {self.formulas[cell]}\")\n",
    "                elif cell in self.labels:\n",
    "                    print(f\"    Label: {self.labels[cell]}\")\n",
    "            print()\n",
    "    \n",
    "    def print_impact_analysis(self, cell):\n",
    "        \"\"\"Print impact analysis for a specific cell\"\"\"\n",
    "        impact = self.analyze_cell_impact(cell)\n",
    "        dependencies = self.trace_cell_dependencies(cell)\n",
    "        \n",
    "        print(f\"=== IMPACT ANALYSIS FOR {cell} ===\")\n",
    "        print(f\"Depends on {len(dependencies)} cells:\")\n",
    "        for dep in dependencies[:10]:  # Show first 10\n",
    "            print(f\"  â† {dep}\")\n",
    "        if len(dependencies) > 10:\n",
    "            print(f\"  ... and {len(dependencies) - 10} more\")\n",
    "        print()\n",
    "        \n",
    "        print(f\"Affects {len(impact)} cells:\")\n",
    "        for imp in impact[:10]:  # Show first 10\n",
    "            print(f\"  â†’ {imp}\")\n",
    "        if len(impact) > 10:\n",
    "            print(f\"  ... and {len(impact) - 10} more\")\n",
    "        print()\n",
    "\n",
    "# Usage example\n",
    "def analyze_excel_dependencies(input_data):\n",
    "    analyzer = ExcelDependencyAnalyzer()\n",
    "    \n",
    "    # Parse input data\n",
    "    if isinstance(input_data, str):\n",
    "        lines = input_data.strip().split('\\n')\n",
    "    else:\n",
    "        lines = input_data\n",
    "    \n",
    "    analyzer.parse_input_data(lines)\n",
    "    \n",
    "    print(f\"Parsed {len(analyzer.formulas)} formulas and {len(analyzer.labels)} labels\")\n",
    "    print(f\"Graph has {analyzer.graph.number_of_nodes()} nodes and {analyzer.graph.number_of_edges()} edges\\n\")\n",
    "    \n",
    "    # Find and display critical paths\n",
    "    analyzer.print_critical_paths()\n",
    "    \n",
    "    # Example impact analysis for a specific cell\n",
    "    outputs = analyzer.find_output_cells()\n",
    "    if outputs:\n",
    "        print(f\"=== SAMPLE IMPACT ANALYSIS ===\")\n",
    "        analyzer.print_impact_analysis(outputs[0])\n",
    "    \n",
    "    return analyzer\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data in your format\n",
    "    sample_data = \"\"\"\n",
    "s2-sf|E11|=C11+D11\n",
    "s2-sf|K11|Mech New\n",
    "s2-sf|C11|=s1-as!B5*1.2\n",
    "s2-sf|D11|=s1-as!B6*0.8\n",
    "s1-as|B5|Base Cost\n",
    "s1-as|B6|Additional Cost\n",
    "s3-ca|A1|=s2-sf!E11*s2-sf!K11\n",
    "s4-ou|Z99|=s3-ca!A1+s2-sf!E11\n",
    "\"\"\"\n",
    "    \n",
    "    analyzer = analyze_excel_dependencies(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c1e4b-9506-4c63-8ead-bed9bd01c4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
